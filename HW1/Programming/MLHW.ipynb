{"cells":[{"cell_type":"markdown","metadata":{"id":"mz0_QVkxCrX3"},"source":["# **2022 ML FALL HW1: PM2.5 Prediction (Regression)**"]},{"cell_type":"markdown","metadata":{"id":"ZeZnPAiwDRWG"},"source":["Author: MLTAs\n","\n","Methods:\n","* Training with all data\n","* Training config: mini-batch=512, optimizer=Adam, learning rate=0.1 (TODO: Change the config!)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"wS_4-77xHk44"},"source":["# **Import Some Packages**"]},{"cell_type":"code","execution_count":138,"metadata":{"executionInfo":{"elapsed":337,"status":"ok","timestamp":1665021020552,"user":{"displayName":"何秉學","userId":"15307262397001925156"},"user_tz":-480},"id":"k-onQd4JNA5H"},"outputs":[],"source":["import numpy as np\n","import csv\n","import math\n","import pandas as pd"]},{"cell_type":"code","execution_count":139,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":147,"status":"ok","timestamp":1665021021059,"user":{"displayName":"何秉學","userId":"15307262397001925156"},"user_tz":-480},"id":"iUIroiX8jBlb","outputId":"06a07680-c85e-47b1-e740-9cce6f9fba95"},"outputs":[{"data":{"text/plain":["'d:\\\\NTU\\\\First Year\\\\Machine Learning\\\\HW\\\\HW1\\\\Programming'"]},"execution_count":139,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","os.getcwd()"]},{"cell_type":"markdown","metadata":{"id":"aqMEWsRekx0L"},"source":["# **Fix random seed**\n","\n","\n","This is for the reproduction of your result. **DO NOT modify this secton!** \n"]},{"cell_type":"code","execution_count":140,"metadata":{"id":"UxDA6fJb_Uem"},"outputs":[],"source":["import random\n","\n","seed = 9487\n","random.seed(seed)"]},{"cell_type":"markdown","metadata":{"id":"0OVRMuTAc1_E"},"source":["# **Download training data**\n"]},{"cell_type":"code","execution_count":141,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1271,"status":"ok","timestamp":1664347474606,"user":{"displayName":"機器學習","userId":"03249990876179673050"},"user_tz":-480},"id":"s0Zo8JUp5kJ4","outputId":"208abac6-741a-4d9e-8136-7be1da9d3385"},"outputs":[],"source":["# !gdown --id \"1Hfzrcm69QwdFvdeF0uASoQlcVxKw_hHy\" --output \"train.csv\"s\n","# !gdown --id '1FXJztppYG9Q4b_4NHvcmPsc4o5obceWC' --output \"test.csv\"\n","\n","# Incase the links above die, you can use the following instead.\n","#!gdown --id '11abE854Eyv4BA7qt5k8r_80sJ3KuOQUN' --output \"train.csv\"\n","# !gdown --id '1uod-Z4ztluXnuHtgUbm39nMudUKqXHMl' --output \"test.csv\"\n","\n","# If the data is still missing, you can manually download it from kaggle, and upload the files under /content"]},{"cell_type":"markdown","metadata":{},"source":["# **Define function**"]},{"cell_type":"code","execution_count":142,"metadata":{"id":"yHpuZmQwXpz8"},"outputs":[],"source":["def valid(x, y):\n","  # TODO: Try to filter out extreme values.\n","  # ex: If PM2.5 > 100, then we don't use the data to train (return False), otherwise return True,\n","\n","  # Total unvalid datas is 24\n","  global count\n","  if x[1][0] > 1.2 or x[2][0] > 40 or x[3][0] > 50 or x[4][0] > 80 or x[6][0] > 200 or x[14][0] > 70:\n","    count += 1\n","    return False\n","  return True\n","\n","\n","# Create your dataset\n","def parse2train(data, feats):\n","\n","  x = []\n","  y = []\n","\n","  # Use data #0~#7 to predict #8 => Total data length should be decresased by 8.\n","  total_length = data.shape[1] - 8  # data.shape[1] == 5774\n","  \n","  for i in range(total_length):\n","    x_tmp = data[feats, i:i+8] # Use data #0~#7 to predict #8, data #1~#8 to predict #9, etc. Feats is row of data and i:i+8 is column of data\n","    y_tmp = data[-1, i+8] # last column of (i+8)th row: PM2.5\n","\n","    # Filter out extreme values to train.\n","    if valid(x_tmp, y_tmp):\n","      x.append(x_tmp.reshape(-1,))\n","      y.append(y_tmp)\n","  \n","\n","  # Total valid datas is 5742\n","  # x.shape: (n, 15, 8)\n","  # y.shape: (n, 1) \n","  x = np.array(x)\n","  y = np.array(y)\n","\n","  return x,y\n"]},{"cell_type":"markdown","metadata":{"id":"WyEpvVVQdZ0c"},"source":["# **Adam**\n","* This is our gradient descent algorithm. Adam was implemented.\n","* You can implement another algorithm such as SGD, which may (or may not) boost the performance.\n","* However, **modules like sklearn and pytorch are not allowed**.\n","* Ref: https://arxiv.org/pdf/1412.6980.pdf\n","![](https://i.imgur.com/jRaebdf.png)\n","\n"]},{"cell_type":"code","execution_count":143,"metadata":{"id":"XL_RVBoLuXvj"},"outputs":[],"source":["# TODO: Implement 2-nd polynomial regression version for the report.\n","def minibatch(x, y, config):\n","  \n","    # Randomize the data in minibatch\n","    index = np.arange(x.shape[0])\n","    np.random.shuffle(index)\n","    x = x[index]\n","    y = y[index]\n","    \n","    # Initialization\n","    batch_size = config.batch_size\n","    lr = config.lr\n","    lam = config.lam\n","    epoch = config.epoch\n","\n","    beta_1 = np.full(x[0].shape, 0.9).reshape(-1, 1)\n","    beta_2 = np.full(x[0].shape, 0.99).reshape(-1, 1)\n","    # Linear regression: only contains two parameters (w, b).\n","    w = np.full(x[0].shape, 0.1).reshape(-1, 1)\n","    bias = 0.1\n","    m_t = np.full(x[0].shape, 0).reshape(-1, 1)\n","    v_t = np.full(x[0].shape, 0).reshape(-1, 1)\n","    m_t_b = 0.0\n","    v_t_b = 0.0\n","    t = 0\n","    epsilon = 1e-8\n","    \n","    # Training loop\n","    for num in range(epoch):\n","        for b in range(int(x.shape[0]/batch_size)):\n","            t+=1\n","            x_batch = x[b * batch_size:(b+1) * batch_size]\n","            y_batch = y[b * batch_size:(b+1) * batch_size].reshape(-1,1)\n","\n","            # Prediction of linear regression \n","            pred = np.dot(x_batch, w) + bias\n","            # loss\n","            loss = y_batch - pred\n","            \n","            # Compute gradient\n","            g_t = np.dot(x_batch.transpose(), loss) * (-2) +  2 * lam * np.sum(w) \n","            g_t_b = loss.sum(axis=0) * (-2)\n","            m_t = beta_1 * m_t + (1-beta_1) * g_t \n","            v_t = beta_2 * v_t + (1-beta_2) * np.multiply(g_t, g_t)\n","            m_cap = m_t / (1-(beta_1**t))\n","            v_cap = v_t / (1 - (beta_2**t))\n","            m_t_b = 0.9 * m_t_b + (1 - 0.9) * g_t_b\n","            v_t_b = 0.99 * v_t_b + (1 - 0.99) * (g_t_b * g_t_b) \n","            m_cap_b = m_t_b / (1 - (0.9**t))\n","            v_cap_b = v_t_b / (1 - (0.99**t))\n","            w_0 = np.copy(w)\n","            \n","            # Update weight & bias\n","            w -= ((lr * m_cap) / (np.sqrt(v_cap) + epsilon)).reshape(-1, 1)\n","            bias -= (lr * m_cap_b) / (math.sqrt(v_cap_b) + epsilon)\n","            \n","\n","    return w, bias"]},{"cell_type":"code","execution_count":144,"metadata":{"id":"ZpdOsMfXLxH2"},"outputs":[],"source":["from argparse import Namespace\n","\n","# TODO: Tune the config to boost your performance. \n","train_config = Namespace(\n","    batch_size = 512,\n","    lr = 1e-1,\n","    lam = 0.001,\n","    epoch = 200,\n",")"]},{"cell_type":"markdown","metadata":{"id":"ay-RhqqA88vS"},"source":["# **Training your regression model**"]},{"cell_type":"code","execution_count":157,"metadata":{"id":"_Akqj5yYVGHA"},"outputs":[],"source":["# Choose your features to train. \n","# Hint: \n","# 1. You can select more than one feature.\n","# 2. You should select \"good\" features.\n","\n","# TODO: Carefully justify which feature should be chosen.\n","# feats = [1, 2, 3, 4, 6, 14] # Choose CO, NO, NO2, NOx, PM2.5, PM10\n","# feats = [0, 5, 7, 8, 9, 10, 11, 12, 13]\n","feats = np.ndarray.tolist(np.arange(15))"]},{"cell_type":"code","execution_count":146,"metadata":{"id":"AiEWGMQXLM99"},"outputs":[],"source":["# Training data preprocessing.\n","data = pd.read_csv(\"./train.csv\")\n","data = data.values  # Data type is <class 'numpy.ndarray'>\n","\n","# To transpose the data to data^T\n","# count = 0\n","train_data = np.transpose(np.array(np.float64(data)))   # Data type is <class 'numpy.ndarray'>\n","train_x, train_y = parse2train(train_data, feats)\n","# print(count)"]},{"cell_type":"code","execution_count":147,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1664347475285,"user":{"displayName":"機器學習","userId":"03249990876179673050"},"user_tz":-480},"id":"HhfoPJUhcnH9","outputId":"5add5fc3-afa9-4ec3-a897-0e1f97060374"},"outputs":[{"name":"stdout","output_type":"stream","text":["(72, 1) (1,)\n"]}],"source":["# Train your regression model\n","\n","w, bias = minibatch(train_x, train_y, train_config)\n","print(w.shape, bias.shape)"]},{"cell_type":"markdown","metadata":{"id":"019GwPMrbmrB"},"source":["# **Testing:**\n"]},{"cell_type":"code","execution_count":148,"metadata":{"id":"5FjQNzOb6BeQ"},"outputs":[],"source":["def parse2test(data, feats):\n","  x = []\n","  for i in range(90):\n","    x_tmp = data[feats, 8*i:8*i+8]\n","    x.append(x_tmp.reshape(-1,))\n","\n","  # x.shape: (n, 15, 8)\n","  x = np.array(x)\n","  return x\n"]},{"cell_type":"code","execution_count":149,"metadata":{"id":"z40o9QbAYbR6"},"outputs":[],"source":["data = pd.read_csv('test.csv')\n","data = data.values\n","\n","test_data = np.transpose(np.array(np.float64(data)))\n","test_x = parse2test(test_data, feats)"]},{"cell_type":"markdown","metadata":{"id":"fWrfEwaEdO6J"},"source":["# **Write result as .csv**\n","\n","---\n","\n"]},{"cell_type":"code","execution_count":150,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":293,"status":"ok","timestamp":1664347481053,"user":{"displayName":"機器學習","userId":"03249990876179673050"},"user_tz":-480},"id":"TqEQ1fZ9-WMO","outputId":"ed060dcc-8be6-4278-9466-bb632ac66a9c"},"outputs":[{"name":"stdout","output_type":"stream","text":["(90, 72)\n"]}],"source":["with open('my_sol.csv', 'w', newline='') as csvf:\n","    # 建立 CSV 檔寫入器\n","    writer = csv.writer(csvf)\n","    writer.writerow(['Id','Predicted'])\n","\n","    print(test_x.shape) \n","    for i in range(int(test_x.shape[0])):\n","      # Prediction of linear regression \n","      prediction = (np.dot(np.reshape(w,-1),test_x[i]) + bias)[0]\n","      writer.writerow([i, prediction] )"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[{"file_id":"1ffy7uvNJr_rtaNbIlGZdrY47TkjzRKx-","timestamp":1665022477970},{"file_id":"1F-E9mHTJXo4heU8tr72UVIiHXR4MNpQi","timestamp":1663000203559},{"file_id":"1feslucFrEPkkuEJyFmPjEiaEhSyKAAmG","timestamp":1662890865314},{"file_id":"1Xj7rpNfdiYwq0R7udY_p13N_2PJfDd8k","timestamp":1662888507120}]},"kernelspec":{"display_name":"Python 3.8.13 ('NTU_ML')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"vscode":{"interpreter":{"hash":"a04df75c32766f3d499272b3c4b6cc9162998ee7afe31618e8fd853f9d59c375"}}},"nbformat":4,"nbformat_minor":0}
