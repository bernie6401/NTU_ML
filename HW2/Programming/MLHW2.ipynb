{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDVwVcC2ofHK"
      },
      "source": [
        "## ML HW2 sample code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rV0FCmEOSz0"
      },
      "source": [
        "#### Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sMsNXtVLopQ2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Bernie\\anaconda3\\envs\\NTU_ML\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import glob\n",
        "import csv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from torch.optim import Adam\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lfyxtZsqrw-_"
      },
      "outputs": [],
      "source": [
        "# !gdown 1drrS7gnyzUJPPiQcDWcHdIXqzjy2n3yZ\n",
        "# !unzip 'HW2.zip'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbV9AEejOSz2"
      },
      "source": [
        "#### Set arguments and random seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U9hIGGaiOSz2"
      },
      "outputs": [],
      "source": [
        "TRA_PATH = './dataset/train/'\n",
        "TST_PATH = './dataset/test/'\n",
        "LABEL_PATH = './dataset/train.csv'\n",
        "DEVICE_ID = 0\n",
        "SEED = 5566\n",
        "NUM_ECPOCH = 10\n",
        "\n",
        "torch.cuda.set_device(DEVICE_ID)\n",
        "use_gpu = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_gpu else \"cpu\")\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "torch.cuda.manual_seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6fQ5BNqozM0"
      },
      "source": [
        "#### Process data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "G7-7syI4L9XE"
      },
      "outputs": [],
      "source": [
        "def load_train_data(img_path, label_path, valid_ratio=0.2):\n",
        "    train_label = pd.read_csv(label_path)['label'].values.tolist()\n",
        "    train_image = [f'{img_path}/{i+10000}.jpg' for i in range(len(train_label)-1)]\n",
        "    \n",
        "    train_data = list(zip(train_image, train_label))\n",
        "    random.shuffle(train_data)\n",
        "    \n",
        "    split_len = int(len(train_data) * valid_ratio)\n",
        "    train_set = train_data[split_len:]\n",
        "    valid_set = train_data[:split_len]\n",
        "    \n",
        "    return train_set, valid_set\n",
        "\n",
        "def load_test_data(img_path):\n",
        "    test_set = [f'{img_path}/{i}.jpg' for i in range(7000, 10000)]\n",
        "    return test_set\n",
        "    \n",
        "def compute_statistics(dataset):\n",
        "    data = []\n",
        "    for (img_path, label) in dataset:\n",
        "        data.append(np.array(Image.open(img_path)))\n",
        "    data = np.array(data)\n",
        "    return data.mean(), data.std()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XyGNv3zQOSz4"
      },
      "outputs": [],
      "source": [
        "train_set, valid_set = load_train_data(TRA_PATH, LABEL_PATH)\n",
        "test_set = load_test_data(TST_PATH)\n",
        "transform = None # do augmentation there"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voXR5jPVPnxp"
      },
      "source": [
        "#### Customize dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VyMfGXwgMWQV"
      },
      "outputs": [],
      "source": [
        "class FaceExpressionDataset(Dataset):\n",
        "    def __init__(self, data, augment=None):\n",
        "        self.data = data\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def normalize(self, data):\n",
        "        # TODO: do normalization there\n",
        "        pass\n",
        "    \n",
        "    def read_img(self, idx):\n",
        "        img = Image.open(self.data[idx][0])\n",
        "        if not self.augment is None:\n",
        "            img = self.augment(img)\n",
        "        img = torch.from_numpy(np.array(img)).float()\n",
        "        img = img.unsqueeze(0).float()\n",
        "        # img = self.normalize(img)\n",
        "        return img\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img = self.read_img(idx)\n",
        "        label = self.data[idx][1]\n",
        "        return img, label\n",
        "    \n",
        "class TestingDataset(Dataset):\n",
        "    def __init__(self, data, augment=None):\n",
        "        self.data = data\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def normalize(self, data):\n",
        "        # TODO: do normalization there\n",
        "        pass\n",
        "    \n",
        "    def read_img(self, idx):\n",
        "        img = Image.open(self.data[idx])\n",
        "        if not self.augment is None:\n",
        "            img = self.augment(img)\n",
        "        img = torch.from_numpy(np.array(img)).float()\n",
        "        img = img.unsqueeze(0).float()\n",
        "        # img = self.normalize(img)\n",
        "        return img, self.data[idx].split('/')[-1][:-4]\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        img, name = self.read_img(idx)\n",
        "        \n",
        "        return img, name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Dm6AqmFzOSz6"
      },
      "outputs": [],
      "source": [
        "train_dataset = FaceExpressionDataset(train_set, transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "\n",
        "valid_dataset = FaceExpressionDataset(valid_set)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "test_dataset = TestingDataset(test_set)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)                  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLA_KBidRF73"
      },
      "source": [
        "#### Define module class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3QwewjIWP39y"
      },
      "outputs": [],
      "source": [
        "class FaceExpressionNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FaceExpressionNet, self).__init__()\n",
        "        # TODO\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64, eps=1e-05, affine=True),\n",
        "            nn.LeakyReLU(negative_slope=0.05),\n",
        "            nn.MaxPool2d((2, 2)),\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(64 * 32 * 32, 7),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        #image size (64,64)\n",
        "        x = self.conv(x) #(32,32)\n",
        "        x = x.flatten(start_dim=1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyyjQS2eOSz7"
      },
      "source": [
        "#### Define training and testing process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oFCMvUe0OSz7"
      },
      "outputs": [],
      "source": [
        "def train(train_loader, model, loss_fn, use_gpu=True):\n",
        "    model.train()\n",
        "    train_loss = []\n",
        "    train_acc = []\n",
        "    for (img, label) in train_loader:\n",
        "        if use_gpu:\n",
        "            img = img.to(device)\n",
        "            label = label.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(img)\n",
        "        loss = loss_fn(output, label)\n",
        "        loss.backward()            \n",
        "        optimizer.step()\n",
        "        with torch.no_grad():\n",
        "            predict = torch.argmax(output, dim=-1)\n",
        "            acc = np.mean((label == predict).cpu().numpy())\n",
        "            train_acc.append(acc)\n",
        "            train_loss.append(loss.item())\n",
        "    print(\"Epoch: {}, train Loss: {:.4f}, train Acc: {:.4f}\".format(epoch + 1, np.mean(train_loss), np.mean(train_acc)))\n",
        "    \n",
        "def valid(valid_loader, model, loss_fn, use_gpu=True):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        valid_loss = []\n",
        "        valid_acc = []\n",
        "        for idx, (img, label) in enumerate(valid_loader):\n",
        "            if use_gpu:\n",
        "                img = img.to(device)\n",
        "                label = label.to(device)\n",
        "            output = model(img)\n",
        "            loss = loss_fn(output, label)\n",
        "            predict = torch.argmax(output, dim=-1)\n",
        "            acc = (label == predict).cpu().tolist()\n",
        "            valid_loss.append(loss.item())\n",
        "            valid_acc += acc\n",
        "       \n",
        "        valid_acc = np.mean(valid_acc)\n",
        "        valid_loss = np.mean(valid_loss)\n",
        "        print(\"Epoch: {}, valid Loss: {:.4f}, valid Acc: {:.4f}\".format(epoch + 1, valid_loss, valid_acc))\n",
        "    return valid_acc\n",
        "\n",
        "def save_checkpoint(valid_acc, acc_record, epoch, prefix='./model/model'):\n",
        "    # you can define the condition to save model :)\n",
        "    if valid_acc >= np.mean(acc_record[-5:]):    \n",
        "        checkpoint_path = f'{prefix}.pth'\n",
        "        torch.save(model.state_dict(), checkpoint_path)\n",
        "        print('model saved to %s' % checkpoint_path)\n",
        "\n",
        "def better(acc_record):\n",
        "    if max(acc_record) == acc_record[-1]: return True\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "pBHN_XSsTF6p"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, train Loss: 5.8139, train Acc: 0.2970\n",
            "Epoch: 1, valid Loss: 2.8791, valid Acc: 0.3077\n",
            "model saved to model.pth\n",
            "########################################################\n",
            "Epoch: 2, train Loss: 2.4906, train Acc: 0.3869\n",
            "Epoch: 2, valid Loss: 2.7625, valid Acc: 0.3774\n",
            "model saved to model.pth\n",
            "########################################################\n",
            "Epoch: 3, train Loss: 2.0865, train Acc: 0.4341\n",
            "Epoch: 3, valid Loss: 2.5708, valid Acc: 0.3832\n",
            "model saved to model.pth\n",
            "########################################################\n",
            "Epoch: 4, train Loss: 1.7875, train Acc: 0.4776\n",
            "Epoch: 4, valid Loss: 2.2167, valid Acc: 0.3910\n",
            "model saved to model.pth\n",
            "########################################################\n",
            "Epoch: 5, train Loss: 1.5112, train Acc: 0.5165\n",
            "Epoch: 5, valid Loss: 2.3324, valid Acc: 0.3846\n",
            "########################################################\n",
            "Epoch: 6, train Loss: 1.4033, train Acc: 0.5376\n",
            "Epoch: 6, valid Loss: 2.0234, valid Acc: 0.4029\n",
            "model saved to model.pth\n",
            "########################################################\n",
            "Epoch: 7, train Loss: 1.2019, train Acc: 0.5815\n",
            "Epoch: 7, valid Loss: 2.0385, valid Acc: 0.4062\n",
            "model saved to model.pth\n",
            "########################################################\n",
            "Epoch: 8, train Loss: 1.0791, train Acc: 0.6125\n",
            "Epoch: 8, valid Loss: 2.1331, valid Acc: 0.4033\n",
            "########################################################\n",
            "Epoch: 9, train Loss: 0.9813, train Acc: 0.6391\n",
            "Epoch: 9, valid Loss: 2.2129, valid Acc: 0.4184\n",
            "model saved to model.pth\n",
            "########################################################\n",
            "Epoch: 10, train Loss: 0.8962, train Acc: 0.6720\n",
            "Epoch: 10, valid Loss: 2.0477, valid Acc: 0.4093\n",
            "########################################################\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    model = FaceExpressionNet()\n",
        "    if use_gpu:\n",
        "        model.to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    \n",
        "    acc_record = []\n",
        "    \n",
        "    for epoch in range(NUM_ECPOCH):\n",
        "        train(train_loader, model, loss_fn, use_gpu)\n",
        "        valid_acc = valid(valid_loader, model, loss_fn, use_gpu=True)\n",
        "        acc_record.append(valid_acc)\n",
        "        \n",
        "        \n",
        "        if better(acc_record):\n",
        "            save_checkpoint(valid_acc, acc_record, epoch, prefix='model')\n",
        "        \n",
        "        print('########################################################')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "AqMcl44nOSz9"
      },
      "outputs": [],
      "source": [
        "def test(test_loader, model, file_name='./testing_result/predict.csv'):\n",
        "    with torch.no_grad():\n",
        "        predict_result = []\n",
        "        predict_name = []\n",
        "        for img, name in test_loader:\n",
        "            if use_gpu:\n",
        "                img = img.to(device)\n",
        "            output = model(img)\n",
        "            predict = torch.argmax(output, dim=-1).tolist()\n",
        "            predict_result += predict\n",
        "            predict_name += name\n",
        "        \n",
        "    with open(file_name, 'w', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow(['id', 'label'])\n",
        "        for id, r in zip(predict_name, predict_result):\n",
        "            writer.writerow([id, r])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZqtDLxvkOSz9"
      },
      "outputs": [],
      "source": [
        "del model\n",
        "model = FaceExpressionNet()\n",
        "model.load_state_dict(torch.load('./model/model.pth'))\n",
        "model = model.cuda()\n",
        "test(test_loader, model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('NTU_ML')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "a04df75c32766f3d499272b3c4b6cc9162998ee7afe31618e8fd853f9d59c375"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
